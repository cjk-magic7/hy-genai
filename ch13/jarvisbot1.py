# pip install streamlit streamlit-audiorecorder openai numpy 

#  pip install streamlit-audiorecorder
# ìœˆë„ìš°ì—ì„œì˜ ffmpeg: conda install -c main ffmpeg
# macì—ì„œì˜ ffmpeg ì„¤ì¹˜: https://www.lainyzine.com/ko/article/how-to-install-ffmpeg-on-mac/
# python version > 3.12 ì´ìƒ

# í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ import
import streamlit as st  # Streamlit íŒ¨í‚¤ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
from audiorecorder import audiorecorder  # ìŒì„± ë…¹ìŒ ê¸°ëŠ¥ì„ ìœ„í•œ íŒ¨í‚¤ì§€
from openai import OpenAI  # OpenAI API ì‚¬ìš©ì„ ìœ„í•œ íŒ¨í‚¤ì§€
import os  # íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•œ os íŒ¨í‚¤ì§€
from datetime import datetime  # ì‹œê°„ ì •ë³´ë¥¼ ë‹¤ë£¨ê¸° ìœ„í•œ datetime íŒ¨í‚¤ì§€
import numpy as np  # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë¹„êµí•˜ê¸° ìœ„í•œ numpy íŒ¨í‚¤ì§€
import base64  # ìŒì› íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©í•˜ê¸° ìœ„í•œ íŒ¨í‚¤ì§€

# ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ ì •ì˜
def convert_speech_to_text(audio_data, openai_client):
    # ìŒì„± íŒŒì¼ì„ 'speech_input.mp3'ë¡œ ì €ì¥
    file_name = 'speech_input.mp3'
    with open(file_name, "wb") as audio_file:
        audio_file.write(audio_data.export().read())

    # ì €ì¥ëœ ìŒì„± íŒŒì¼ì„ ì—´ê¸°
    with open(file_name, "rb") as audio_file:
        try:
            # OpenAIì˜ Whisper APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            transcription = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                response_format="text"
            )
            # ë³€í™˜ì´ ì™„ë£Œë˜ë©´ íŒŒì¼ ì‚­ì œ
            os.remove(file_name)
        except:
            transcription = 'API Keyë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”'
    return transcription

# í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ ì •ì˜
def convert_text_to_speech(response_text, openai_client):
    # OpenAI TTS ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
    tts_response = openai_client.audio.speech.create(
        model="tts-1",
        voice="nova",
        input=response_text
    )
    output_file = "speech_output.mp3"
    tts_response.stream_to_file(output_file)

    # ë³€í™˜ëœ ìŒì„± íŒŒì¼ì„ ìë™ ì¬ìƒí•˜ê¸° ìœ„í•´ base64ë¡œ ì¸ì½”ë”©
    with open(output_file, "rb") as audio_file:
        audio_data = audio_file.read()
        base64_audio = base64.b64encode(audio_data).decode()
        audio_html = f"""
            <audio autoplay="True">
            <source src="data:audio/mp3;base64,{base64_audio}" type="audio/mp3">
            </audio>
        """
        st.markdown(audio_html, unsafe_allow_html=True)
    # ì¬ìƒ í›„ íŒŒì¼ ì‚­ì œ
    os.remove(output_file)

# GPT-3.5 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì–»ëŠ” í•¨ìˆ˜ ì •ì˜
def get_gpt_response(prompt_list, openai_client):
    response = openai_client.chat.completions.create(model='gpt-3.5-turbo', messages=prompt_list)
    return response.choices[0].message.content

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì¸ê³µì§€ëŠ¥ ë¹„ì„œ ìë¹„ìŠ¤",
    layout="wide"
)

# session state ì´ˆê¸°í™”
if "conversation" not in st.session_state:
    st.session_state["conversation"] = []

if "previous_audio" not in st.session_state:
    st.session_state["previous_audio"] = []

if "prompts" not in st.session_state:
    st.session_state["prompts"] = [{"role": "system", "content": 'You are a thoughtful assistant. Respond to all input in 25 words and answer in korean'}]

# í˜ì´ì§€ ì œëª© ì„¤ì •
st.header('ì¸ê³µì§€ëŠ¥ ë¹„ì„œ ìë¹„ìŠ¤ì…ë‹ˆë‹¤')
st.subheader('ì œê°€ ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ¤–')
st.markdown('---')

# OpenAI API í‚¤ ì§€ì •
openai_client = OpenAI(
    api_key = "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"
)

start_flag = False

# Streamlit ë ˆì´ì•„ì›ƒ ì„¤ì •
left_column, right_column = st.columns(2)
with left_column:
    # ìŒì„± ë…¹ìŒ ê¸°ëŠ¥
    recorded_audio = audiorecorder("ì§ˆë¬¸í•˜ê¸°", "ë“£ê³  ìˆëŠ” ì¤‘ì…ë‹ˆë‹¤...")
    if len(recorded_audio) > 0 and not np.array_equal(recorded_audio, st.session_state["previous_audio"]):
        # ë…¹ìŒëœ ìŒì„±ì„ ì¬ìƒ
        st.audio(recorded_audio.export().read())

        # ë…¹ìŒëœ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        user_question = convert_speech_to_text(recorded_audio, openai_client)

        # ëŒ€í™” ë‚´ìš©ì„ ê¸°ë¡í•˜ê¸° ìœ„í•´ í˜„ì¬ ì‹œê°„ì„ ê°€ì ¸ì˜¤ê¸°
        current_time = datetime.now().strftime("%H:%M")
        st.session_state["conversation"] = st.session_state["conversation"] + [("user", current_time, user_question)]
        
        # GPT ëª¨ë¸ì— ì…ë ¥í•  í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸
        st.session_state["prompts"] = st.session_state["prompts"] + [{"role": "user", "content": user_question}]
        
        # í˜„ì¬ ë…¹ìŒëœ ìŒì„±ì„ ì €ì¥í•˜ì—¬ ë‹¤ìŒ ë…¹ìŒê³¼ ë¹„êµ
        st.session_state["previous_audio"] = recorded_audio
        start_flag = True

with right_column:
    # ëŒ€í™” ê¸°ë¡ì„ ìœ„í•œ ê³µê°„
    st.image('ai.png', width=100)
    st.subheader('ëŒ€í™”ê¸°ë¡ âŒ¨')
    if start_flag:
        # GPT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ì–»ê¸°
        ai_response = get_gpt_response(st.session_state["prompts"], openai_client)

        # í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸
        st.session_state["prompts"] = st.session_state["prompts"] + [{"role": "assistant", "content": ai_response}]
        
        # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸
        current_time = datetime.now().strftime("%H:%M")
        st.session_state["conversation"] = st.session_state["conversation"] + [("bot", current_time, ai_response)]

        # ëŒ€í™” ê¸°ë¡ì„ ì±„íŒ… í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
        for sender, time, message in st.session_state["conversation"]:
            if sender == "user":
                st.write(f'<div style="display:flex;align-items:center;"><div style="background-color:#007AFF;color:white;border-radius:12px;padding:8px 12px;margin-right:8px;">{message}</div><div style="font-size:0.8rem;color:gray;">{time}</div></div>', unsafe_allow_html=True)
                st.write("")
            else:
                st.write(f'<div style="display:flex;align-items:center;justify-content:flex-end;"><div style="background-color:lightgray;border-radius:12px;padding:8px 12px;margin-left:8px;">{message}</div><div style="font-size:0.8rem;color:gray;">{time}</div></div>', unsafe_allow_html=True)
                st.write("")
        
        # TTSë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜ ë° ì¬ìƒ
        convert_text_to_speech(ai_response, openai_client)
