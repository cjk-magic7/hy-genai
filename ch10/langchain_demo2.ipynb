{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNWXK2BvapRd"
      },
      "outputs": [],
      "source": [
        "# Langsmith : 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\n",
        "# OpenAI.   : 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"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# https://github.com/langchain-ai/langchain/tree/master/cookbook\n",
        "\n",
        "Langchain CookBook 예제 확인하기\n"
      ],
      "metadata": {
        "id": "ogDSH2aYpAKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# langchain 패키지 설치\n",
        "!pip install langchain"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IM6X2askasMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LangSmith 설정\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()\n",
        "\n",
        "print(os.environ[\"LANGCHAIN_API_KEY\"])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yOaNexX0bNlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 언어 모델별 Langchain 패키지 설치 (openai)\n",
        "!pip install -qU langchain-openai"
      ],
      "metadata": {
        "id": "CuLczaZgnzCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI API 키 셋팅\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n"
      ],
      "metadata": {
        "id": "LKN17TMfn1-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Math chain**\n",
        "수학 체인 이 노트북은 LLM 및 Python REPL을 사용하여 복잡한 단어 수학 문제를 해결하는 방법을 보여줍니다."
      ],
      "metadata": {
        "id": "pl-HFLJt4Ojr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMMathChain\n",
        "from langchain_openai import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "llm_math = LLMMathChain.from_llm(llm, verbose=True)\n",
        "\n",
        "llm_math.invoke(\"What is 13 raised to the .3432 power?\")"
      ],
      "metadata": {
        "id": "1MWZbptp4WxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SmartLLMChain**\n",
        "\n",
        "SmartLLMChain은 답변해야 할 특히 복잡한 질문이 있는 경우 도움이 될 수 있는 일종의 자기 비판 체인입니다. 단일 LLM 패스를 수행하는 대신 다음 3단계를 수행합니다. 아이디어: LLM을 통해 사용자 프롬프트를 n번 전달하여 n개의 출력 제안(\"아이디어\"라고 함)을 얻습니다. 여기서 n은 설정할 수 있는 매개 변수입니다. 비판: LLM 가능한 결함을 찾기 위해 모든 아이디어를 비판하고 가장 좋은 아이디어를 선택합니다. 해결: LLM은 최고의 아이디어(비평 단계에서 선택한 대로)를 개선하고 이를 출력합니다. 이것이 최종 출력입니다."
      ],
      "metadata": {
        "id": "4fl2pmOK4f5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_experimental"
      ],
      "metadata": {
        "id": "M_Bqtt195bJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_experimental.smart_llm import SmartLLMChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "hard_question = \"저는 12리터짜리 주전자와 6리터짜리 주전자를 가지고 있습니다. 6리터를 측정하고 싶습니다. 어떻게 해야 하나요?\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(hard_question)\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4\")\n",
        "\n",
        "chain = SmartLLMChain(llm=llm, prompt=prompt, n_ideas=3, verbose=True)\n",
        "chain.invoke({})"
      ],
      "metadata": {
        "id": "4zb2PCON4-qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OpenAI V1 기능 살펴보기**\n",
        "\n",
        "23년 11월 6일에 OpenAI는 여러 가지 새로운 기능을 출시했으며 이와 함께 Python SDK를 1.0.0으로 올렸습니다. 이 노트북은 LangChain의 새로운 기능과 이를 사용하는 방법을 보여줍니다."
      ],
      "metadata": {
        "id": "9yAoUjlI6trR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# need openai>=1.1.0, langchain>=0.0.335, langchain-experimental>=0.0.39\n",
        "# !pip install -U openai langchain langchain-experimental"
      ],
      "metadata": {
        "id": "o1Ae7NMx5ZTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Vision\n",
        "chat = ChatOpenAI(model=\"gpt-4o\", max_tokens=256)\n",
        "chat.invoke(\n",
        "    [\n",
        "        HumanMessage(\n",
        "            content=[\n",
        "                {\"type\": \"text\", \"text\": \"이미지의 내용 설명해줘\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": \"https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/static/img/langchain_stack.png\",\n",
        "                        \"detail\": \"auto\",\n",
        "                    },\n",
        "                },\n",
        "            ]\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "qRpH799l6_uB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}